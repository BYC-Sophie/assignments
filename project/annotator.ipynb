{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d91258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score, precision_score, recall_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346181b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"annotator.csv\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "953a5626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  gpt5  annotator1  annotator2\n",
      "0         1.1     0           0           0\n",
      "1         1.2     0           0           0\n",
      "2         1.3     0           0           0\n",
      "3         1.4     0           0           0\n",
      "4         1.5     1           0           0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40137618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen’s kappa:\n",
      "GPT-5 vs Annotator 1: 0.324\n",
      "GPT-5 vs Annotator 2: 0.380\n",
      "Annotator 1 vs Annotator 2: 0.451\n"
     ]
    }
   ],
   "source": [
    "kappa_gpt5_annot1 = cohen_kappa_score(df[\"gpt5\"], df[\"annotator1\"])\n",
    "kappa_gpt5_annot2 = cohen_kappa_score(df[\"gpt5\"], df[\"annotator2\"])\n",
    "kappa_annot1_annot2 = cohen_kappa_score(df[\"annotator1\"], df[\"annotator2\"])\n",
    "\n",
    "print(\"Cohen’s kappa:\")\n",
    "print(f\"GPT-5 vs Annotator 1: {kappa_gpt5_annot1:.3f}\")\n",
    "print(f\"GPT-5 vs Annotator 2: {kappa_gpt5_annot2:.3f}\")\n",
    "print(f\"Annotator 1 vs Annotator 2: {kappa_annot1_annot2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edf6bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt5\n",
      "0    0.570248\n",
      "1    0.429752\n",
      "Name: proportion, dtype: float64\n",
      "annotator1\n",
      "0    0.752066\n",
      "1    0.247934\n",
      "Name: proportion, dtype: float64\n",
      "annotator2\n",
      "0    0.834711\n",
      "1    0.165289\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"gpt5\"].value_counts(normalize=True))\n",
    "print(df[\"annotator1\"].value_counts(normalize=True))\n",
    "print(df[\"annotator2\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e00f323b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kappa</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Union (recall-oriented)</th>\n",
       "      <td>0.404</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strict (precision-oriented)</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.269</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             kappa     f1  precision  recall  accuracy\n",
       "Union (recall-oriented)      0.404  0.614      0.519    0.75     0.719\n",
       "Strict (precision-oriented)  0.296  0.424      0.269    1.00     0.686"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "# 2. Compute human unions\n",
    "df[\"human_union\"] = ((df[\"annotator1\"] == 1) | (df[\"annotator2\"] == 1)).astype(int)\n",
    "df[\"human_strict\"] = ((df[\"annotator1\"] == 1) & (df[\"annotator2\"] == 1)).astype(int)\n",
    "df[\"human_mean\"]   = df[[\"annotator1\",\"annotator2\"]].mean(axis=1)\n",
    "\n",
    "# 3. Define a helper function\n",
    "def evaluate(ref_col):\n",
    "    kappa = cohen_kappa_score(df[\"gpt5\"], df[ref_col])\n",
    "    f1 = f1_score(df[ref_col], df[\"gpt5\"])\n",
    "    precision = precision_score(df[ref_col], df[\"gpt5\"])\n",
    "    recall = recall_score(df[ref_col], df[\"gpt5\"])\n",
    "    accuracy = accuracy_score(df[ref_col], df[\"gpt5\"])\n",
    "    return {\"kappa\": kappa, \"f1\": f1, \"precision\": precision, \"recall\": recall, \"accuracy\": accuracy}\n",
    "\n",
    "# 4. Compare GPT-5 to both aggregate human references\n",
    "results = {\n",
    "    \"Union (recall-oriented)\": evaluate(\"human_union\"),\n",
    "    \"Strict (precision-oriented)\": evaluate(\"human_strict\")\n",
    "}\n",
    "\n",
    "# 5. Display nicely\n",
    "pd.DataFrame(results).T.round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f2996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annotator2\n",
       "0    0.834711\n",
       "1    0.165289\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
