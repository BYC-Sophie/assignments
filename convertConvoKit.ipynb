{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd79eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.venv/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: convokit in ./.venv/lib/python3.12/site-packages (3.4.1)\n",
      "Requirement already satisfied: ipykernel in ./.venv/lib/python3.12/site-packages (6.30.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.12/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.12/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in ./.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in ./.venv/lib/python3.12/site-packages (from convokit) (3.10.6)\n",
      "Requirement already satisfied: scipy>1.14 in ./.venv/lib/python3.12/site-packages (from convokit) (1.16.1)\n",
      "Requirement already satisfied: msgpack-numpy>=0.4.3.2 in ./.venv/lib/python3.12/site-packages (from convokit) (0.4.8)\n",
      "Requirement already satisfied: spacy>=3.8.2 in ./.venv/lib/python3.12/site-packages (from convokit) (3.8.7)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in ./.venv/lib/python3.12/site-packages (from convokit) (1.7.1)\n",
      "Requirement already satisfied: nltk>=3.4 in ./.venv/lib/python3.12/site-packages (from convokit) (3.9.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in ./.venv/lib/python3.12/site-packages (from convokit) (1.5.2)\n",
      "Requirement already satisfied: clean-text>=0.6.0 in ./.venv/lib/python3.12/site-packages (from convokit) (0.6.0)\n",
      "Requirement already satisfied: unidecode>=1.1.1 in ./.venv/lib/python3.12/site-packages (from convokit) (1.4.0)\n",
      "Requirement already satisfied: pymongo>=4.0 in ./.venv/lib/python3.12/site-packages (from convokit) (4.14.1)\n",
      "Requirement already satisfied: dnspython>=1.16.0 in ./.venv/lib/python3.12/site-packages (from convokit) (2.7.0)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in ./.venv/lib/python3.12/site-packages (from convokit) (8.3.6)\n",
      "Requirement already satisfied: h5py==3.12.1 in ./.venv/lib/python3.12/site-packages (from convokit) (3.12.1)\n",
      "Requirement already satisfied: numexpr>=2.8.0 in ./.venv/lib/python3.12/site-packages (from convokit) (2.11.0)\n",
      "Requirement already satisfied: ruff>=0.4.8 in ./.venv/lib/python3.12/site-packages (from convokit) (0.12.11)\n",
      "Requirement already satisfied: bottleneck in ./.venv/lib/python3.12/site-packages (from convokit) (1.5.0)\n",
      "Requirement already satisfied: appnope>=0.1.2 in ./.venv/lib/python3.12/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.12/site-packages (from ipykernel) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (9.5.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in ./.venv/lib/python3.12/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.12/site-packages (from ipykernel) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.12/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in ./.venv/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in ./.venv/lib/python3.12/site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in ./.venv/lib/python3.12/site-packages (from ipykernel) (27.0.2)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.venv/lib/python3.12/site-packages (from ipykernel) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from clean-text>=0.6.0->convokit) (1.7.0)\n",
      "Requirement already satisfied: ftfy<7.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from clean-text>=0.6.0->convokit) (6.3.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.9)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->convokit) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->convokit) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->convokit) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->convokit) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->convokit) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.0.0->convokit) (3.2.3)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in ./.venv/lib/python3.12/site-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.1.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk>=3.4->convokit) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk>=3.4->convokit) (2025.8.29)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.0->convokit) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (3.0.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (0.17.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (80.9.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.12/site-packages (from spacy>=3.8.2->convokit) (3.5.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in ./.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.0->convokit) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.0->convokit) (0.1.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.3.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (0.22.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (7.3.0.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->spacy>=3.8.2->convokit) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./.venv/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (4.0.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (1.17.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets convokit ipykernel\n",
    "# parsed with spacy en_core_web_sm: \"python -m spacy download en_core_web_sm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7571e",
   "metadata": {},
   "source": [
    "### Download original dataset from huggingface\n",
    "\n",
    "Detailed introduction to the datasets is on \"https://huggingface.co/datasets/audreyeleven/MentalManip\"\n",
    "\n",
    "There are three seperate files on MentalManip repo: mentalmanip_detialed.csv, mentalmanip_con.csv, and mentalmanip_maj.csv.\n",
    "\n",
    "Here, we use the processed mentalmanip_con.csv version which contains final gold labels the authors generated from the 3 annotators' results using Consensus agreement strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd52993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byc324/Desktop/24Fall/25Fall/communication/assignment1/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/byc324/Desktop/24Fall/25Fall/communication/assignment1/.venv/lib/python3.12/site-packages/convokit/coordination/coordination.py:5: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerDecoderModel requires ML dependencies. Run 'pip install convokit[llm]' to install them.\n",
      "TransformerEncoderModel requires ML dependencies. Run 'pip install convokit[llm]' to install them.\n",
      "An error occurred: No module named 'torch'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byc324/Desktop/24Fall/25Fall/communication/assignment1/.venv/lib/python3.12/site-packages/convokit/__init__.py:31: UserWarning: If you are using ConvoKit with Google Colab, incorrect versions of some packages (ex. scipy) may be imported while runtime start. To fix the issue, restart the session and run all codes again. Thank you!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from convokit import Corpus, Speaker, Utterance, Conversation\n",
    "from collections import defaultdict\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c934e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some datasets params were ignored: ['license']. Make sure to use only valid params for the dataset builder and to have a up-to-date version of the `datasets` library.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"audreyeleven/MentalManip\", \"mentalmanip_con\") # or \"mentalmanip_maj\", \"mentalmanip_detailed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae62e8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'manipulative', 'technique', 'vulnerability'],\n",
       "        num_rows: 2915\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f5dfe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'dialogue', 'manipulative', 'technique', 'vulnerability'])\n",
      "Person1: Jesus! Listen to this one: \"Do you remember me? Airport shuttle, June 7th. You: striking redhead with yellow dress, pearl necklace, brown shoes. I was the bookish fellow in the green cardigan who helped you find your contact lens. Am I crazy, or did we have a moment?\"\n",
      "Person2: God, that's so pathetic. I bet she didn't even notice him.\n",
      "Person1: I know. And he's like psychotically obsessing over every little detail.\n",
      "Person2: We should call him and pretend to be the redhead.\n",
      "Person1: Oh, we totally have to.\n"
     ]
    }
   ],
   "source": [
    "ds = dataset[\"train\"]\n",
    "row0 = ds[0]\n",
    "print(row0.keys())\n",
    "print(row0[\"dialogue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54759cd",
   "metadata": {},
   "source": [
    "### Dataset pre-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "374f8d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manipulative counts:\n",
      "manipulative\n",
      "0     899\n",
      "1    2016\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Technique counts:\n",
      "Persuasion or Seduction    607\n",
      "Shaming or Belittlement    384\n",
      "Accusation                 361\n",
      "Intimidation               321\n",
      "Rationalization            213\n",
      "Brandishing Anger          133\n",
      "Denial                      87\n",
      "Evasion                     83\n",
      "Playing Victim Role         69\n",
      "Feigning Innocence          58\n",
      "Playing Servant Role        30\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Vulnerability counts:\n",
      "Dependency                  282\n",
      "Low self-esteem             155\n",
      "Naivete                      94\n",
      "Over-responsibility          93\n",
      "Over-intellectualization     46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = ds.to_pandas()\n",
    "\n",
    "# manipulative\n",
    "print(\"Manipulative counts:\")\n",
    "print(df[\"manipulative\"].value_counts().sort_index())\n",
    "\n",
    "# split function\n",
    "def split_and_flatten(series):\n",
    "    values = []\n",
    "    for item in series.dropna():\n",
    "        for part in str(item).split(\",\"):\n",
    "            part = part.strip()\n",
    "            if part:\n",
    "                values.append(part)\n",
    "    return pd.Series(values)\n",
    "\n",
    "# technique\n",
    "print(\"\\nTechnique counts:\")\n",
    "print(split_and_flatten(df[\"technique\"]).value_counts())\n",
    "\n",
    "# vulnerability\n",
    "print(\"\\nVulnerability counts:\")\n",
    "print(split_and_flatten(df[\"vulnerability\"]).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bac7bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manipulative=1 but technique is NULL: 268\n",
      "manipulative=1 with >1 techniques: 543\n"
     ]
    }
   ],
   "source": [
    "# 1) sanity check: manipulative=1 but technique is null\n",
    "m1_no_tech = df[(df[\"manipulative\"] == 1) & (df[\"technique\"].isna() | (df[\"technique\"].str.strip() == \"\"))]\n",
    "print(\"manipulative=1 but technique is NULL:\", len(m1_no_tech))\n",
    "\n",
    "# 2) manipulative=1 and technique >1\n",
    "df[\"num_techniques\"] = df[\"technique\"].fillna(\"\").apply(lambda x: len([t.strip() for t in str(x).split(\",\") if t.strip()]))\n",
    "m1_multi = df[(df[\"manipulative\"] == 1) & (df[\"num_techniques\"] > 1)]\n",
    "print(\"manipulative=1 with >1 techniques:\", len(m1_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fda5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "002b5ba7",
   "metadata": {},
   "source": [
    "### Function to convert each conversation to separate turns for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1666d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSON_RE = re.compile(r\"(Person\\d+):\\s*\")\n",
    "\n",
    "def parse_dialogue(raw: str):\n",
    "    parts = PERSON_RE.split(raw)\n",
    "    turns = []\n",
    "    cur_speaker = None\n",
    "    for chunk in parts:\n",
    "        if not chunk:\n",
    "            continue\n",
    "        if chunk.startswith(\"Person\"):\n",
    "            cur_speaker = chunk  # e.g., Person1\n",
    "        else:\n",
    "            text = chunk.strip()\n",
    "            if not text:\n",
    "                continue\n",
    "            if cur_speaker is None:\n",
    "                if turns:\n",
    "                    turns[-1] = (turns[-1][0], turns[-1][1] + \" \" + text)\n",
    "                else:\n",
    "                    turns.append((\"Person1\", text))\n",
    "            else:\n",
    "                turns.append((cur_speaker, text))\n",
    "    return turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f71d8dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Person1', 'Jesus! Listen to this one: \"Do you remember me? Airport shuttle, June 7th. You: striking redhead with yellow dress, pearl necklace, brown shoes. I was the bookish fellow in the green cardigan who helped you find your contact lens. Am I crazy, or did we have a moment?\"'), ('Person2', \"God, that's so pathetic. I bet she didn't even notice him.\"), ('Person1', \"I know. And he's like psychotically obsessing over every little detail.\"), ('Person2', 'We should call him and pretend to be the redhead.'), ('Person1', 'Oh, we totally have to.')]\n"
     ]
    }
   ],
   "source": [
    "turns = parse_dialogue(row0[\"dialogue\"])\n",
    "print(turns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff74d144",
   "metadata": {},
   "source": [
    "### Function to biuld speakers and utterances\n",
    "\n",
    "Note: In the dataset, speakers within each conversation are labeled generically as Person1, Person2, etc. To avoid conflating these roles across different conversations, we treat them as distinct entities and prepend the conversation ID to each speaker ID, thereby uniquely associating speakers with their respective conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e487e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_speakers(row_id, turns):\n",
    "    speakers = {}\n",
    "    for spk_label, _ in turns:\n",
    "        sid = f\"{row_id}__{spk_label}\"\n",
    "        if sid not in speakers:\n",
    "            speakers[sid] = Speaker(id=sid, meta={\"role_label\": spk_label})\n",
    "    return speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fec201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_utterances(row_id, turns, speakers):\n",
    "    utterances, prev_utt_id = [], None\n",
    "    root_utt_id = f\"{row_id}__u0\" \n",
    "    for turn_idx, (spk_label, text) in enumerate(turns):\n",
    "        spk_id = f\"{row_id}__{spk_label}\"\n",
    "        utt_id = f\"{row_id}__u{turn_idx}\"\n",
    "        utterances.append(\n",
    "            Utterance(\n",
    "                id=utt_id,\n",
    "                text=text,\n",
    "                speaker=speakers[spk_id],\n",
    "                conversation_id=root_utt_id,\n",
    "                reply_to=prev_utt_id,\n",
    "                timestamp=turn_idx,                \n",
    "                # meta={\"turn_index\": turn_idx}\n",
    "            )\n",
    "        )\n",
    "        prev_utt_id = utt_id\n",
    "    return utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73837745",
   "metadata": {},
   "source": [
    "### Build Speakers and Utterances\n",
    "\n",
    "Number of Speakers: 5830\n",
    "\n",
    "Number of Utterances: 19232\n",
    "\n",
    "Number of Conversations: 2915\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52cd5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_utts = []\n",
    "all_speakers = {}\n",
    "\n",
    "for row in ds:\n",
    "    row_id = str(row[\"id\"])\n",
    "    turns = parse_dialogue(row[\"dialogue\"])  \n",
    "\n",
    "    # Speakers\n",
    "    local_speakers = build_speakers(row_id, turns)\n",
    "    for sid, spk in local_speakers.items():\n",
    "        all_speakers.setdefault(sid, spk)  # 合并进全局\n",
    "\n",
    "    # Utterances\n",
    "    all_utts.extend(build_utterances(row_id, turns, all_speakers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d5f3325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of speakers in the data = 5830\n"
     ]
    }
   ],
   "source": [
    "print(\"number of speakers in the data = {}\".format(len(all_speakers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "223d4b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of utterances = 19232\n",
      "Jesus! Listen to this one: \"Do you remember me? Airport shuttle, June 7th. You: striking redhead with yellow dress, pearl necklace, brown shoes. I was the bookish fellow in the green cardigan who helped you find your contact lens. Am I crazy, or did we have a moment?\"\n",
      "None\n",
      "85514414__u0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of utterances = {}\".format(len(all_utts)))\n",
    "print(all_utts[0].text)\n",
    "print(all_utts[0].reply_to)\n",
    "print(all_utts[0].id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04ab3e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "God, that's so pathetic. I bet she didn't even notice him.\n",
      "85514414__u0\n",
      "85514414__u1\n"
     ]
    }
   ],
   "source": [
    "print(all_utts[1].text)\n",
    "print(all_utts[1].reply_to)\n",
    "print(all_utts[1].id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de616f2b",
   "metadata": {},
   "source": [
    "### Build corpus from utterances list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff61d7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configuration file found at /Users/byc324/.convokit/config.yml; writing with contents: \n",
      "# Default Backend Parameters\n",
      "db_host: localhost:27017\n",
      "data_directory: ~/.convokit/saved-corpora\n",
      "model_directory: ~/.convokit/saved-models\n",
      "default_backend: mem\n",
      "number of conversations in the dataset = 2915\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(utterances=all_utts)\n",
    "print(\"number of conversations in the dataset = {}\".format(len(corpus.get_conversation_ids())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d038155d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample conversation 85514414__u0:\n",
      "['85514414__u0', '85514414__u1', '85514414__u2', '85514414__u3', '85514414__u4']\n",
      "sample conversation 85514415__u0:\n",
      "['85514415__u0', '85514415__u1', '85514415__u2', '85514415__u3', '85514415__u4']\n",
      "sample conversation 85514416__u0:\n",
      "['85514416__u0', '85514416__u1', '85514416__u2', '85514416__u3', '85514416__u4', '85514416__u5', '85514416__u6']\n",
      "sample conversation 85514417__u0:\n",
      "['85514417__u0', '85514417__u1', '85514417__u2', '85514417__u3', '85514417__u4', '85514417__u5', '85514417__u6', '85514417__u7']\n",
      "sample conversation 85514418__u0:\n",
      "['85514418__u0', '85514418__u1', '85514418__u2', '85514418__u3', '85514418__u4', '85514418__u5', '85514418__u6']\n"
     ]
    }
   ],
   "source": [
    "convo_ids = corpus.get_conversation_ids()\n",
    "for i, convo_idx in enumerate(convo_ids[0:5]):\n",
    "    print(\"sample conversation {}:\".format(convo_idx))\n",
    "    print(corpus.get_conversation(convo_idx).get_utterance_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3429e7",
   "metadata": {},
   "source": [
    "### Add meta data for the conversations in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "271a418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in ds:\n",
    "    row_id = str(row[\"id\"])\n",
    "    root_id = f\"{row_id}__u0\"\n",
    "    conv_meta = {\n",
    "        \"manipulative\": int(row[\"manipulative\"]),\n",
    "        \"technique\": (row.get(\"technique\") or \"\").split(\",\") if row.get(\"technique\") else [],\n",
    "        \"vulnerability\": (row.get(\"vulnerability\") or \"\").split(\",\") if row.get(\"vulnerability\") else []\n",
    "    }\n",
    "    convo = corpus.get_conversation(root_id)\n",
    "    convo.meta.update(conv_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8619e681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvoKitMeta({'manipulative': 1, 'technique': ['Rationalization', 'Accusation', 'Shaming or Belittlement'], 'vulnerability': ['Low self-esteem']})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_conversation(\"85514447__u0\").meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73e600b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.meta['name'] = \"MentalManip_con\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1844a",
   "metadata": {},
   "source": [
    "### Parse the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20b32afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit.text_processing import TextParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "717e6095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/19232 utterances processed\n",
      "19232/19232 utterances processed\n"
     ]
    }
   ],
   "source": [
    "parser = TextParser(verbosity=10000)\n",
    "parsed_corpus = parser.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66cc4f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rt': 1,\n",
       "  'toks': [{'tok': 'All', 'tag': 'RB', 'dep': 'advmod', 'up': 1, 'dn': []},\n",
       "   {'tok': 'right', 'tag': 'RB', 'dep': 'ROOT', 'dn': [0, 2]},\n",
       "   {'tok': '.', 'tag': '.', 'dep': 'punct', 'up': 1, 'dn': []}]},\n",
       " {'rt': 0,\n",
       "  'toks': [{'tok': 'Tell', 'tag': 'VB', 'dep': 'ROOT', 'dn': [1, 3, 6]},\n",
       "   {'tok': \"'em\", 'tag': 'PRP', 'dep': 'dobj', 'up': 0, 'dn': []},\n",
       "   {'tok': 'to', 'tag': 'TO', 'dep': 'aux', 'up': 3, 'dn': []},\n",
       "   {'tok': 'shoot', 'tag': 'VB', 'dep': 'xcomp', 'up': 0, 'dn': [2, 5]},\n",
       "   {'tok': 'to', 'tag': 'TO', 'dep': 'aux', 'up': 5, 'dn': []},\n",
       "   {'tok': 'kill', 'tag': 'VB', 'dep': 'xcomp', 'up': 3, 'dn': [4]},\n",
       "   {'tok': '.', 'tag': '.', 'dep': 'punct', 'up': 0, 'dn': []}]}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_corpus.get_utterance('85514417__u0').retrieve_meta('parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f0ae447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"All right. Tell 'em to shoot to kill.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_corpus.get_utterance('85514417__u0').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0762518",
   "metadata": {},
   "source": [
    "### Save the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b752f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_corpus.dump(\"mentalmanip-corpus\", base_path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93368f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "400fb3cb",
   "metadata": {},
   "source": [
    "### Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660030bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2915\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=\"./mentalmanip-corpus\")\n",
    "print(len(list(corpus.iter_conversations())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a47947ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 5830\n",
      "Number of Utterances: 19232\n",
      "Number of Conversations: 2915\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030b405d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation('id': '85514573__u0', 'utterances': ['85514573__u0', '85514573__u1', '85514573__u2', '85514573__u3', '85514573__u4', '85514573__u5'], 'meta': ConvoKitMeta({'manipulative': 1, 'technique': ['Persuasion or Seduction'], 'vulnerability': ['Low self-esteem']}))\n"
     ]
    }
   ],
   "source": [
    "convo = corpus.random_conversation()\n",
    "print(convo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3dbbb4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85516233__Person1\n",
      "    85516233__Person2\n"
     ]
    }
   ],
   "source": [
    "convo.print_conversation_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd5a8430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker(id: '85515593__Person2', vectors: [], meta: ConvoKitMeta({'role_label': 'Person2'}))\n"
     ]
    }
   ],
   "source": [
    "speaker = corpus.random_speaker()\n",
    "print(speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d137c66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jesus! Listen to this one: \"Do you remember me? Airport shuttle, June 7th. You: striking redhead with yellow dress, pearl necklace, brown shoes. I was the bookish fellow in the green cardigan who helped you find your contact lens. Am I crazy, or did we have a moment?\"\n"
     ]
    }
   ],
   "source": [
    "for utt in corpus.iter_utterances():\n",
    "    print(utt.text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c1d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed682bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
